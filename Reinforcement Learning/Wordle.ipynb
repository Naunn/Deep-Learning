{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_wordle\n",
    "import random\n",
    "import numpy as np\n",
    "from gym_wordle.utils import to_array, to_english\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available():    True\n",
      "torch.cuda.current_device():  0\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51002045/how-to-make-jupyter-notebook-to-run-on-gpu\n",
    "# https://www.techentice.com/how-to-make-jupyter-notebook-to-run-on-gpu/\n",
    "import tensorflow as tf\n",
    "tf.test.is_built_with_cuda()\n",
    "# https://stackoverflow.com/questions/57814535/assertionerror-torch-not-compiled-with-cuda-enabled-in-spite-upgrading-to-cud\n",
    "# https://stackoverflow.com/questions/57238344/i-have-a-gpu-and-cuda-installed-in-windows-10-but-pytorchs-torch-cuda-is-availa\n",
    "import torch\n",
    "print(\"torch.cuda.is_available():    {}\".format(torch.cuda.is_available()))\n",
    "print(\"torch.cuda.current_device():  {}\".format(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(12972)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"Wordle-v0\")\n",
    "env = env.unwrapped \n",
    "env.reset()\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([[0 0 0 0 0 0 0 0 0 0]\n",
       " [0 0 0 0 0 0 0 0 0 0]\n",
       " [0 0 0 0 0 0 0 0 0 0]\n",
       " [0 0 0 0 0 0 0 0 0 0]\n",
       " [0 0 0 0 0 0 0 0 0 0]\n",
       " [0 0 0 0 0 0 0 0 0 0]], [[26 26 26 26 26  4  4  4  4  4]\n",
       " [26 26 26 26 26  4  4  4  4  4]\n",
       " [26 26 26 26 26  4  4  4  4  4]\n",
       " [26 26 26 26 26  4  4  4  4  4]\n",
       " [26 26 26 26 26  4  4  4  4  4]\n",
       " [26 26 26 26 26  4  4  4  4  4]], (6, 10), int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space\n",
    "# character flag codes\n",
    "# no_char = 0\n",
    "# right_pos = 1\n",
    "# wrong_pos = 2\n",
    "# wrong_char = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amiss 73\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 3, 3, 3, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "solution = env.solution\n",
    "print(to_english(env.solution_space[solution]),solution)\n",
    "# act = env.action_space.sample()\n",
    "# step = env.step(env.solution)\n",
    "word = \"cocky\"\n",
    "act = env.unwrapped.action_space.index_of(to_array(word))\n",
    "obs, reward, done, _ = env.step(act)\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 10000\n",
      "Iteration: 20000\n",
      "Iteration: 30000\n",
      "Iteration: 40000\n",
      "Iteration: 50000\n",
      "Iteration: 60000\n",
      "Iteration: 70000\n",
      "Iteration: 80000\n",
      "Iteration: 90000\n",
      "Iteration: 100000\n",
      "========== Summary ==========\n",
      "Number of successes: 0\n",
      "Success rate: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# bazowe uczenie (na farta)\n",
    "env = gym.make('Wordle-v0')\n",
    "\n",
    "success = 0\n",
    "i = 0\n",
    "limit = 100_000\n",
    "reward = -1\n",
    "\n",
    "while True:\n",
    "\n",
    "    if i % 10_000 == 0:\n",
    "        print(\"Iteration: {}\".format(i))\n",
    "    if i == limit:\n",
    "        break\n",
    "\n",
    "    env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        # make a random guess\n",
    "        act = env.action_space.sample()\n",
    "\n",
    "        # take a step\n",
    "        obs, reward, done, info = env.step(act)\n",
    "\n",
    "    if reward > 0:\n",
    "        env.render()\n",
    "        success += 1\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "env.close()\n",
    "print(\"========== Summary ==========\")\n",
    "print(\"Number of successes: {}\".format(success))\n",
    "print(\"Success rate: {}%\".format(success/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6        |\n",
      "|    ep_rew_mean      | -6       |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    episodes         | 25000    |\n",
      "|    fps              | 14736    |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 150000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6        |\n",
      "|    ep_rew_mean      | -6       |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 50000    |\n",
      "|    fps              | 11506    |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 299950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0814   |\n",
      "|    n_updates        | 1248     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6        |\n",
      "|    ep_rew_mean      | -6       |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 75000    |\n",
      "|    fps              | 8490     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 449940   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 4998     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6        |\n",
      "|    ep_rew_mean      | -6       |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100000   |\n",
      "|    fps              | 7453     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 599910   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0477   |\n",
      "|    n_updates        | 8747     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6        |\n",
      "|    ep_rew_mean      | -6       |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 125000   |\n",
      "|    fps              | 6871     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 749900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 12497    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6        |\n",
      "|    ep_rew_mean      | -6       |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 150000   |\n",
      "|    fps              | 6602     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 899870   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 16246    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6        |\n",
      "|    ep_rew_mean      | -6       |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 175000   |\n",
      "|    fps              | 6427     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 1049850  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 19996    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6        |\n",
      "|    ep_rew_mean      | -6       |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200000   |\n",
      "|    fps              | 6253     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 1199830  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 23745    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.98     |\n",
      "|    ep_rew_mean      | -5.97    |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    episodes         | 225000   |\n",
      "|    fps              | 6156     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 1349780  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00934  |\n",
      "|    n_updates        | 27494    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6        |\n",
      "|    ep_rew_mean      | -6       |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 250000   |\n",
      "|    fps              | 6076     |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 1499720  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0258   |\n",
      "|    n_updates        | 31242    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html\n",
    "# stable_baselines3.dqn.MlpPolicy - Policy class with Q-Value Net and target net for DQN\n",
    "\n",
    "# Parallel environments\n",
    "def train_DQN(epoch: int):\n",
    "    # Create a wrapped, monitored VecEnv\n",
    "    # https://stable-baselines3.readthedocs.io/en/master/common/env_util.html\n",
    "    env = make_vec_env(\"Wordle-v0\", n_envs=10)\n",
    "\n",
    "    \"\"\"Deep Q-Network (DQN)\n",
    "\n",
    "    Default hyperparameters are taken from the Nature paper,\n",
    "    except for the optimizer and learning rate\n",
    "    that were taken from Stable Baselines defaults.\n",
    "\n",
    "    Paper: https://arxiv.org/abs/1312.5602, https://www.nature.com/articles/nature14236\n",
    "    \"\"\"\n",
    "\n",
    "    model = DQN(\n",
    "        policy=\"MlpPolicy\",          # the policy model to use (MlpPolicy, CnnPolicy, MultiInputPolicy)\n",
    "        env=env,                     # the environment to learn from (if registered in Gym, can be str)\n",
    "        learning_rate=5e-4,          # the learning rate, it can be a function of the current progress remaining (from 1 to 0)\n",
    "        buffer_size=10000,           # size of the replay buffer\n",
    "        learning_starts=epoch//100,  # how many steps of the model to collect transitions for before learning starts\n",
    "        gamma=0.99,                  # the discount factor\n",
    "        train_freq=4,                # update the model every train_freq steps\n",
    "        target_update_interval=1000, # update the target network every target_update_interval environment steps\n",
    "        exploration_fraction=1,      # fraction of entire training period over which the exploration rate is reduced\n",
    "        exploration_final_eps=0.5,   # final value of random action probability\n",
    "        verbose=1,                   # 0 for no output, 1 for info messages, 2 for debug messages\n",
    "        device='cuda',               # device (cpu, cuda, â€¦) on which the code should be run\n",
    "    )\n",
    "    try:\n",
    "        \n",
    "        # Return a trained model\n",
    "        model.learn(\n",
    "            total_timesteps=epoch,   # the total number of samples (env steps) to train on\n",
    "            log_interval=epoch//1000 # the number of timesteps before logging.\n",
    "        )\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    # Save all the attributes of the object and the model parameters in a zip-file\n",
    "    model.save(\"wordle_dqn\")\n",
    "\n",
    "    return model\n",
    "\n",
    "train_DQN(25_000_000)\n",
    "# CPU => 8m 33.7s (1_000_000);\n",
    "# CUDA => 3m 35.7s (1_000_000);\n",
    "# CUDA => 35m 22.1s (10_000_000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x1fb49613d60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from a zip-file.\n",
    "model = DQN.load(\"wordle_dqn\", device='cuda')\n",
    "# Warning: load re-creates the model from scratch,\n",
    "# it does not update it in-place!\n",
    "# For an in-place load use set_parameters instead.\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: evade\n",
      "Word: toddy\n",
      "CCBAC\n",
      "     \n",
      "     \n",
      "     \n",
      "     \n",
      "     \n",
      "Word: reens\n",
      "CCBAC\n",
      "CBBCC\n",
      "     \n",
      "     \n",
      "     \n",
      "     \n",
      "Word: razed\n",
      "CCBAC\n",
      "CBBCC\n",
      "CBCBB\n",
      "     \n",
      "     \n",
      "     \n",
      "Word: slang\n",
      "CCBAC\n",
      "CBBCC\n",
      "CBCBB\n",
      "CCACC\n",
      "     \n",
      "     \n",
      "Word: faurd\n",
      "CCBAC\n",
      "CBBCC\n",
      "CBCBB\n",
      "CCACC\n",
      "CBCCB\n",
      "     \n",
      "Word: sidhe\n",
      "CCBAC\n",
      "CBBCC\n",
      "CBCBB\n",
      "CCACC\n",
      "CBCCB\n",
      "CCBCA\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Wordle-v0\")\n",
    "obs = env.reset()\n",
    "\n",
    "print(\"Solution:\",to_english(env.solution_space[env.solution]))\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    action, _states = model.predict(obs)\n",
    "    print(\"Word:\",to_english(env.action_space[action]))\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 10000\n",
      "Iteration: 20000\n",
      "Iteration: 30000\n",
      "Iteration: 40000\n",
      "Iteration: 50000\n",
      "Iteration: 60000\n",
      "Iteration: 70000\n",
      "Iteration: 80000\n",
      "Iteration: 90000\n",
      "Iteration: 100000\n",
      "========== Summary ==========\n",
      "Number of successes: 0\n",
      "Success rate: 0.0%\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Wordle-v0')\n",
    "\n",
    "success = 0\n",
    "i = 0\n",
    "limit = 100_000\n",
    "reward = -1\n",
    "\n",
    "while True:\n",
    "\n",
    "    if i % 10_000 == 0:\n",
    "        print(\"Iteration: {}\".format(i))\n",
    "    if i == limit:\n",
    "        break\n",
    "\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "\n",
    "    if reward > 0:\n",
    "        env.render()\n",
    "        success += 1\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "env.close()\n",
    "print(\"========== Summary ==========\")\n",
    "print(\"Number of successes: {}\".format(success))\n",
    "print(\"Success rate: {}%\".format(success/i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym_env",
   "language": "python",
   "name": "gym_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fe3e463de132c429cee0c53a81217854f4ef39ce4247c4bb179d216dafc3da0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
